---
description: 
type: Notes
noteType: experience
source:
title: 响应面分析
aliases:
memo:
created: 2025-11-19
modified: 2025-11-22
tags:
  - 统计方法
cssclasses:
---

> [!important] 相关代码文件说明
> 1. 模拟出的数据文件见 `rsm_data_2factors.csv`；
> 2. 相关 R 代码见 `rsm_practice.R`、`rsm_practice_lm.R`、`rsm_practice_ggplot.R`。
> 	1. rsm_practice.R：使用了 `rsm` 包拟合响应面模型，使用 `persp` 画 3D 响应面图；
> 	2. rsm_practice_lm.R：使用了 `lm` 包拟合响应面模型，使用 Bootstrap 法求 CI，计算 P11；
> 	3. rsm_practice_ggplot.R：使用了 `rsm` 包拟合响应面模型，使用 `ggplot2` 绘制等高线图，使用 `plotly` 绘制可交互式 3D 响应面图。

### 1. 简单介绍

响应面分析 (Response Surface Methodology, RSM) 是用来探究变量**一致性假设**的 (Congruence hpotheses) 一种统计和数学方法 [^1]，用于优化工程和科学问题中的多个变量影响，即用来研究因子 (影响因素 $X_1,\,X_2$) 与过程输出 (响应变量 $Y$) 之间是否存在**二次项关系** (such as, $X_1$🔼,$X_2$🔼时，⏬[一致变化]；$X_1$🔼,$X_2$🔽时，🔽[不一致变化])[^1]，进而能够找到影响某一特定响应 (输出变量) 的最佳组合条件 [^2] [^3]。

以往的一些以线性假设为基础的正交设计，主要解决“有没有差异 ($t$ 检验)”、“独立的线性效应 (回归分析)”[^4] 的问题。当遇到“想要知道 $X_1$ 和 $X_2$ 的哪种搭配影响 $Y$ 的效果最好”的问题时，以往的这些方法就难以实现，比如要进行更复杂的实验设计、收集更复杂结构的数据。因此采用探究非线性设计的 RSM 会更能验证我们的想法。

> [!example]- 多元线性回归 vs. 响应面分析
> 简单说：多元线性回归会告诉你 “糖和奶越多，奶茶评分可能越高”，但它看不到 “糖多到一定程度，再多加奶，评分反而会降”—— 而这种 “变量搭配着变，结果会反转” 的情况，就是你想了解的 “$X_1$ 和 $X_2$ 不一致变化的影响”，多元线性回归抓不到，但响应面能。
>
> **一、先拿 “奶茶配方” 举例子：明确 3 个角色**
> 咱们设定：
> - $X_1$ = 奶茶里的糖量 (比如 10g、20g、30g)
> - $X_2$ = 奶茶里的奶量 (比如 50ml、100ml、150ml)
> - $Y$ = 顾客对奶茶的评分 (1-10 分，分数越高越好)
> 
> 现在要分析：糖和奶怎么加，顾客评分最高？
>
> **二、多元线性回归的 “局限”：它只能看到 “简单加法”**
> 假设我们收集了一些数据，用多元线性回归算出的公式可能是：$Y$ = 3 + 0.2$X_1$ + 0.1$X_2$(意思是：糖每多 10g，评分 + 2；奶每多 50ml，评分 + 5)
> - 它假设 “糖和奶对评分的影响是独立的”：不管糖加了多少，奶每多 50ml 都固定加 5 分；不管奶加了多少，糖每多 10g 都固定加 2 分。
> 
> 但是，它看不到 “搭配翻车” 的情况：比如糖加了 30g(已经很甜了)，再把奶从 100ml 加到 150ml，实际顾客会觉得 “又甜又腻”，评分反而从 8 分降到 5 分 —— 但按线性回归的公式，这时候评分应该继续涨，和真实情况完全不符。
> - 它找不到 “最优搭配”：线性回归会告诉你 “糖和奶越多越好”，但实际奶茶肯定有个最佳比例 (比如 20g 糖 + 100ml 奶)，再多就会翻车，这点它算不出来。
> 
> **三、响应面分析的 “优势”：它能看到 “搭配的门道”**
> 响应面会加入 “非线性项” 和 “交互项”，算出的公式可能是：$Y$ = 2 + 0.5$X_1$ + 0.3$X_2$ - 0.01$X_1^2$ - 0.005$X_2^2$ - 0.002$X_1X_2$
> 这些额外的项，就是用来捕捉 “不一致变化” 的：
> - 用 “-0.01$X_1^2$”“-0.005$X_2^2$” 捕捉 “单个变量加太多会翻车”：比如糖从 10g 加到 20g，评分涨；但从 20g 加到 30g，因为有 “-0.01$X_1^2$” 的抵消，评分反而降。
> - 用 “-0.002$X_1$$X_2$” 捕捉 “糖和奶的搭配问题”：比如糖少的时候 (10g)，多加奶 (从 50ml 到 100ml)，评分涨；但糖多的时候 (30g)，再加奶，“-0.002$X_1$$X_2$” 的负向影响会变大，评分直接降 —— 这就是 “$X_1$ 和 $X_2$ 不一致变化对 $Y$ 的影响”。
> 
> 最后能画出 3D 曲面图：图上会有一个 “最高点”，直接对应 “20g 糖 + 100ml 奶” 这个最优配方，一眼就能看到哪种搭配最好。
>
> **四、一句话总结：两者的核心区别**
> 多元线性回归：像在说 “糖是好东西，奶是好东西，所以加得越多越好”，看不到 “好东西加太多、搭错了，反而会变坏”。
> 响应面分析：像在说 “糖加 10-20g 最好，奶加 80-120ml 最好，而且 20g 糖配 100ml 奶的时候，味道最绝”，能精准找到 “变量搭配的最优解”，也能看到 “搭配错了会翻车”。

考虑到 RSM 分析的特点，为了保证数据分布均匀，即在每周一致条件下都分布均匀，使用传统的“全因子设计”[^5] 会导致数据量翻倍，成本变高；如果是随机抽样，则可能会导致丢失“关键区域”，而且由于随机点分布不均，拟合出的响应面可能严重偏离真实情况。为此，需要采用**中心复合设计 (CCD)** 或者 **Box-Behnken 设计**收集数据，其中 CCD 更常使用。

1. 中心复合设计 (CCD)：4$\times$ 因子点 (极端组合) + 4$\times$ 轴向点 (半极端) + 5$\times$ 中心点 (重复)
	- 因子点：$X_1$、$X_2$ 均取极端值，如 $X_1$(10g/30g)、$X_2$(50ml/150ml)，组合为 (10,50)、(10,150)、(30,50)、(30,150)；确定自变量的 “边界范围”，捕捉极端组合对 $Y$ 的影响 (如糖 10g + 奶 50ml 时满意度最低)。
	- 轴向点：一个自变量取极端值，另一个取中间值 ($X_{1中}$ = 20g，$X_{2中}$ = 100ml)，组合为 (10,100)、(30,100)、(20,50)、(20,150)。专门拟合二次非线性效应 (如 $X_1$ 从 10g→20g→30g 时，满意度先升后降)，是 CCD 能捕捉非线性的关键。
	- 中心点：$X_1$、$X_2$ 均取中间值 (20,100)，重复 5 次。检验实验误差 (如 5 次结果差异小，说明数据可靠)，提升模型拟合精度。
2. Box-Behnken 设计：8$\times$ 中间组合点 + 3$\times$ 中心点 (重复)
	- 中间组合点：$X_1$、$X_2$ 均取 “中间偏极端” 值 (非极值)，如 $X_1$(15g/25g)、$X_2$(75ml/125ml)，组合为 (15,75)、(15,125)、(25,75)、(25,125)，再加上 (15,100)、(25,100)、(20,75)、(20,125)。在安全区间内覆盖 “所有中间组合”，既能捕捉交互效应，也能拟合非线性，且无极端值风险。
	- 中心点：$X_1$、$X_2$ 均取中间值 (20,100)，重复 3 次。与 CCD 类似，检验误差、提升拟合精度，但重复次数比 CCD 少 (因 BBD 数据分布更均匀，误差更小)。

### 2. 统计原理

#### 2.1. LOC 与 LOIC

响应面分析通常是基于多元二次回归模型，通过设计实验收集数据，然后拟合回归方程来描述因素与响应之间的关系 (最小二乘法)。模型形式通常为 ($Y$ 是因变量，$X$ 是自变量，$e$ 是残差；$b_1$ 和 $b_2$ 体现的是线性效应，$b_3$ 和 $b_5$ 体现的是曲线效应，$b_4$ 体现的是交互效应 [^6])：$$Y=b_0+b_1X_1+b_2X_2+b_3X_1^2+b_4X_1X_2+b_5X_2^2+e$$

这式子的图形化就是一个曲面，即 $Y$ 为某值时，($X_1$, $X_2$) 的取值，并形成一个点。所有 ($X_1$, $X_2$) 点都落在曲面上，即响应面。根据 $X_1$ 和 $X_2$ 的一致情况，可以在图中找到两条由 ($X_1$, $X_2$) 点组成的曲线 [^7]，

1. **一致性线 Line of congruence (LOC)**：即 $X_1$ 与 $X_2$ 相同时；
2. **不一致线 Line of incongruence (LOIC)**：即 $X_1$ 与 $X_2$ 互为相反数时。

<img src="https://i.postimg.cc/R0wH9bnQ/xiang-ying-mian-fen-xi.png" width="400" />

通过建立这样的一个含二次项的回归方程，就可以避免复杂设计，直接通过查看响应面的形状或者多项式模型的系数 [^1] 就可以知道自变量之间的交互对因变量的影响，

1. 一致时 ($X_1 = X_2$, $P = A$)，$a_1=b_1+b_2,\,a_2=b_3+b_4+b_5$，因此方程可变为： $Y=b_0+ a_1X+ a_2X^2+e$
	1. $a_1$ 决定了 LOC 的斜率：正负决定 “$X_1$ 和 $X_2$ 一起增加时，$Y$ 是整体上升 (正) 还是下降 (负)”；若与 0 无显著差异，则表示 $X_1$ 和 $X_2$ 一致变化对 $Y$ 的线性影响极弱，主要看非线性效应，即 $a_2$。
	2. $a_2$ 决定了 LOC 是直线还是曲线：正负决定 “$Y$ 随一致变化是否呈 U 型 (正) 或倒 U 型 (负)”；若与 0 无显著差异，则表明 $Y$ 随一致变化接近线性 (无明显拐点)，此时主要看 $a_1$ 的方向，比如 $a_1>0$ 则一直涨。
	- 总体上看，用 “$a_1$ 看整体方向，$a_2$ 看是否有最优值”
		- $a_1>0、a_2<0$ → $Y$ 先升后降，存在 “一致变化的最优搭配”；
		- $a_1<0、a_2>0$ → $Y$ 先降后升，存在 “一致变化的最差搭配”。
2. 相反时 ($X_1 = -X_2$, $P = -A$)，$a_3=b_1-b_2,\,a_4=b_3-b_4+b_5$，因此方程可变为： $Y=b_0+ a_3X+ a_4X^2+e$
	1. $a_3$ 决定了 LOC 的斜率：正负决定 “$X_1$ 比 $X_2$ 大时，$Y$ 是整体更高 (正) 还是更低 (负)；若与 0 无显著差异，则表明 $X_1$ 和 $X_2$ 的 “不一致偏向” 对 $Y$ 的线性影响弱 (类似左右对称)，主要看非线性效应，即 $a_4$。
	2. $a_4$ 决定了 LOC 是直线还是曲线：正负决定 “$Y$ 随 $X_1$、$X_2$ 的‘不一致程度’是否呈 U 型 (正) 或倒 U 型 (负)”—— 即 “轻微不一致” 和 “极度不一致” 对 Y 的影响是否不同；若与 0 无显著差异，则表明 $Y$ 随 “不一致程度” 接近线性 (“极度不一致”比“轻微不一致”的影响只强不弱)。
	- 总体上看，用 $a_3$ 看“哪种不一致更好”，$a_4$ 看“不一致到什么程度会翻车”，比如：
		- $a_3>0、a_4<0$ → 糖多奶少比糖少奶多好，但极度不一致 (不管哪种) 评分都低；
		- $a_3<0、a_4<0$ → 糖少奶多比糖多奶少好，且极度不一致 (糖多或奶多) 评分都低 —— 即 “越平衡越好”。

#### 2.2. FPA

虽然 RSM 常假设最佳 (或最差) 结果沿着 LOC 出现，但多项式面 $z = b_0 + b_1X + b_2Y + b_3X^2 + b_4XY + b_5Y^2$ 的 **“第一主轴/脊线” (first principal axis, FPA)** 未必恰好落在 LOC 上 (此处的自变量为 $X$、$Y$，因变量为 $z$)。二次响应面一般不具备“交换对称性” (即把 X 和 Y 互换，模型保持不变)，而且只要这种对称性被打破，响应面的 FPA 就不会恰好沿着 LOC。

> [!note]- 为什么会偏移 (Shanock et al., 2010；Humberg et al., 2019) ？
> - 模型与几何背景
>     - 二次面：z = b0 + b1X + b2Y + b3X² + b4XY + b5Y²(通常先对 X、Y 做均值中心化，量尺一致)
>     - FPA 的方向由二阶项决定 (Hessian 或二次型的特征向量)，而 LOC 是固定的 45° 直线 (y=x)
> - 为什么会“旋转”(P11 ≠ 1)
>     - FPA 的方向角 θ 满足：θ = 0.5·atan2(b4, b3 − b5)
>     - 只有当 b3 = b5(X、Y 的二阶曲率完全相同) 时，θ=45°，FPA 才可能与 LOC 平行/重合
>     - 一旦 b3 ≠ b5(X、Y 的弯曲程度不同) 或存在交互 b4 ≠ 0，二次面的主轴就会偏离 45°，于是 FPA 与 LOC 产生夹角
> - 为什么会“平移”(P10 ≠ 0)
>     - 一阶项不对称 (b1 ≠ b2) 会把脊线整体推离原点与 LOC 的交点，即出现截距式的偏移
>     - 更形式化地说，二次面的平移由驻点 (x0, y0) 决定，而 FPA 必经驻点；当 b1 ≠ b2 时，(x0, y0) 往往不在 LOC 上：
>         - 解线性方程组可得驻点：
>             - 2b3 x0 + b4 y0 = −b1
>             - b4 x0 + 2b5 y0 = −b2
>         - 已知 FPA 的斜率 m = tan θ，则其截距 P10 = y0 − m·x0；b1 ≠ b2 通常导致 P10 ≠ 0
>     - 直观理解：如果提升 X 的边际效应和提升 Y 的边际效应不同 (b1 与 b2 不同)，最佳 (或最差) 组合不再出现在 X=Y 这条线上
> - 何时两者会对齐 (FPA 与 LOC 重合)
>     - 理论上需要同时满足：
>         - 方向对齐：b3 = b5 ⇒ θ=45° ⇒ P11=1
>         - 位置对齐：b1 = b2(在居中/等量尺前提下)⇒ 驻点落在 LOC 上 ⇒ P10=0
>     - 这实质上就是“把 X、Y 互换，模型形式不变”的交换对称性条件
> - 还会有哪些“看起来的偏差”
>     - 量尺或中心不一致：未做均值中心化、标准化会让 LOC 的几何参照失真，FPA 看上去更偏
>     - 抽样误差：即便总体满足对称，样本估计也会出现小幅 P10、P11 偏离；应报告置信区间并检验 H0: P10=0 与 H0: P11=1
> 
> 与报告实践的联系
> - 这就是为什么 Humberg 等 (2019) 建议在 RSA 中显式报告 P10(平移) 与 P11(旋转)，并检验它们是否分别等于 0 与 1；仅仅在 LOC/LOIC 上报告斜率/曲率不会告诉你“脊线是否就在 LOC 上”。
> - Shanock 等 (2010) 也强调应检查脊线位置与方向，而不是默认“相合线”成立。

$P_{10}$ (平移/截距) 与 $P_{11}$ (旋转/斜率) 给出 FPA 在 $X-Y$ 平面中的直线方程 $y = P_{10} + P_{11}\times x$，从而直接刻画它相对 LOC 的偏移与倾斜 [^8]，下面为相关的定义，

- $P_{10}$ 是在 (均值中心化/标准化) 坐标系中的“截距式平移”，表示 FPA 相对 LOC 是否整体上移/下移。
- $P_{11}$ 是“旋转/斜率”，$P_{11}=1$ 表示与 LOC 平行或重合；$P_{11}<1$ 或 $>1$ 表示与 LOC 的夹角变化 (结合图分析，$>1$ 应该是 FPA 偏向左侧，即 $X<Y$；$<1$ 应该是 FPA 偏向右侧，即 $X>Y$)；若 $P_{11}\approx -1$，则 FPA 近似沿 LOIC，提示“差异/不一致性”方向上出现极值。

$P_{10}$、$P_{11}$ 的可解释性依赖于对 $X$、$Y$ 的居中与量尺一致。Humberg 等 (2019) 建议在报告里说明变量预处理 (如均值中心化/标准化) 并为 $P_{10}$、$P_{11}$ 提供区间估计 (可用 Delta 方法或自助法)。极端或退化情形 (如 $b_4 \approx0$) 下可通过 Hessian 的特征向量稳健求得 FPA。

判断 FPA 和 LOC 是否重合的关键，

- 若 $P_{10}=0$ 且 $P_{11}=1$，则 FPA 与 LOC 重合 (仅仅报告 LOC 或 LOIC 的斜率/曲率 ($a_1$~$a_4$) 并不能保证这一点)。
- 若 $P_{10} \ne 0$ (平移) 或 $P_{11}\ne1$ (旋转)，则极值脊线偏离 LOC。此时将 LOC 上的结果误解为“相合最好/最差”会产生偏差。

Humberg 等人 (2019) 建议的报告内容 [^8]，

- 在报告里除了 $b_1$~$b_5$、$R^2$、以及 LOC/LOIC 的 $a_1$～$a_4$ 外，务必增加：
    - FPA 方程：$y = P_{10} + P_{11} \times x$ (报告估计值与 95%CI)；
    - FPA 与 LOC 的合一检验：联合检验 $P_{10}=0$ 且 $P_{11}=1$；
    - 3D/等高线图上同时画出 LOC、LOIC 与 FPA。
- 若联合原假设被拒绝 (即 FPA 不在 LOC 上)，应将解释从“相合效应”转为“极值脊线偏离 LOC 的模式”，并据此讨论理论含义 (为何最佳/最差并不发生在 $X \approx Y$，而是在某种偏差组合上)。

### 3. 使用 R 进行响应面分析

#### 3.1. 参数估计

##### 3.1.1. 模型拟合

在 R 中主要使用 `rsm` 包来实现，通过如下代码实现模型定义，`fit <- rsm(y ~ FO(x1, x2, x3), data = data)`，且其结果可以使用 `summary` 和 `print` 函数输出。

在定义模型的时候，我们需要注意 `F0` `TWI` `PQ` `SO` `PE` 这些可以定义的部分，一般来说直接使用 `SO` 即可。

- FO(...)：一阶 (first‑order) 主效应，等同于把各因子的线性项列入模型：x1 + x2 + ...
- TWI(...)：two‑way interactions，列出所有两两交互项 (成对乘积)：x1:x2 + x1:x3 + ...
- PQ(...)：pure quadratic，纯二次项 (每个因子的平方)，不包含交互：I(x1^2) + I(x2^2) + ...
- SO(...)：econd‑order，二阶全模型的快捷写法，等价于 FO(...) + TWI(...) + PQ(...)(线性 + 交互 + 平方)
- PE(...)：polynomial effects，用来指定更高阶或正交多项式效应 (用于多项式扩展)。具体语义/参数依 rsm 版本而异，推荐查看帮助页确认用法。

```R
#导入R包
library(rsm)

# 读取数据，并将数据赋值到data变量中
data <- read.csv("C:/Users/admin/Desktop/暂存/001-留中/R 响应面分析/rsm_data_2factors.csv")

# 定义模型，SO包括线性、交互和平方项
rsm <- rsm(Y ~ SO(X1, X2), data = data)

# 输出拟合的信息
summary(rsm)
```

除此之外，我们也可以使用 `lm` 包进行方程的拟合，`fit <- lm(Y ~ X1 + X2 + I(X1^2) + I(X2^2) + I(X1*X2), data = data)`[^9]。其中 `I()` 函数在方程中用来表示非线性项，`X1^2` 和 `X2^2` 是二次项，`X1*X2` 表示 `X1` 和 `X2` 的交互项。通过查看模型摘要，我们可以评估每个项对模型的贡献以及它们是否显著。

```R
data <- read.csv("C:/Users/admin/Desktop/暂存/001-留中/R 响应面分析/rsm_data_2factors.csv")
fit <- lm(Y ~ X1 + X2 + I(X1^2) + I(X2^2) + I(X1*X2), data = data)
summary(fit)
```

##### 3.1.2 计算 CI

要注意的是，无论使用 `rsm` 包还是 `lm` 包，都不会输出回归系数以及驻点的 $CI$，因此需要手动写 Bootstrap 代码估计 CI。下面的例子采用 `lm` 包做演示，实际两个包算出的回归系数等信息是一致的。

```R
data <- read.csv("C:/Users/admin/Desktop/暂存/001-留中/R 响应面分析/rsm_data_2factors.csv")
fit <- lm(Y ~ X1 + X2 + I(X1^2) + I(X2^2) + I(X1*X2), data = data)
summary(fit)


## Bootstrap法求置信区间（稳健实现：用 lm，保留成功样本数）
## -----------------------------
set.seed(20251117)                       # 固定随机种子，保证结果可复现
B_success <- 1000                         # 希望得到的成功 bootstrap 数（成功拟合并返回所需系数）
max_attempts <- B_success * 10           # 最多尝试次数（防止无限循环）
n <- nrow(data)                          # 原始样本量

# 我们期望的系数名称顺序，用于把每次拟合的系数对齐到相同列
coef_names <- c("(Intercept)", "X1", "X2", "I(X1^2)", "I(X2^2)", "I(X1 * X2)")
p <- length(coef_names)

# 预分配存放 bootstrap 结果的矩阵（提高效率）
boot_coefs <- matrix(NA_real_, nrow = B_success, ncol = p, dimnames = list(NULL, coef_names))
# 存放每次成功拟合计算出的驻点（X1, X2）
boot_xs <- matrix(NA_real_, nrow = B_success, ncol = 2)
colnames(boot_xs) <- c("X1", "X2")

attempts <- 0L; successes <- 0L
# 主循环：不断重抽样直到获得足够多的“成功”样本或达到尝试上限
while (successes < B_success && attempts < max_attempts) {
  attempts <- attempts + 1L
  # 有放回重抽样，得到与原样本同样大小的 bootstrap 样本
  idx <- sample.int(n, size = n, replace = TRUE)
  datb <- data[idx, , drop = FALSE]

  # 用 lm 拟合二次模型（这里比 rsm 更稳健，避免 rsm 对某些样本返回 aliased 警告）
  fitb <- try(lm(Y ~ X1 + X2 + I(X1^2) + I(X2^2) + I(X1 * X2), data = datb), silent = TRUE)
  if (inherits(fitb, "try-error")) next   # 若拟合失败则跳过该次重抽样

  cb <- coef(fitb)   # 本次拟合得到的系数向量
  # 检查本次拟合是否包含我们需要的关键项（X1, X2 与二次项）
  req_ok <- all(c("X1","X2") %in% names(cb) & 
                any(grepl("I\\(X1\\^2\\)|X1\\^2", names(cb))) & 
                any(grepl("I\\(X2\\^2\\)|X2\\^2", names(cb))))
  if (!req_ok) next  # 若缺少关键系数（可能由共线/别名导致），跳过

  # 把本次系数填入固定顺序的向量 tmp，缺失的位置保留 NA
  tmp <- rep(NA_real_, p); names(tmp) <- coef_names
  tmp[names(cb)] <- as.numeric(cb)
  successes <- successes + 1L
  boot_coefs[successes, ] <- tmp

  # 提取二次项与交叉项，注意模型系数可能以不同名字出现（I(...) 或 X^2）
  c11 <- if (!is.na(tmp["I(X1^2)"])) tmp["I(X1^2)"] else tmp["X1^2"]
  c22 <- if (!is.na(tmp["I(X2^2)"])) tmp["I(X2^2)"] else tmp["X2^2"]
  c12 <- tmp["I(X1 * X2)"]
  bvec <- c(tmp["X1"], tmp["X2"])  # 线性项向量

  # 构造二次型矩阵 C（注意交叉项在矩阵中放 c12/2）
  Cmat <- matrix(c(as.numeric(c11), as.numeric(c12)/2,
                   as.numeric(c12)/2, as.numeric(c22)), nrow = 2, byrow = TRUE)

  # 求驻点 xs = -0.5 * solve(C, b)，用 try 捕获奇异矩阵等数值错误
  xs_try <- try(-0.5 * solve(Cmat, bvec), silent = TRUE)
  if (!inherits(xs_try, "try-error") && all(is.finite(xs_try))) {
    boot_xs[successes, ] <- as.numeric(xs_try)
  } else {
    # 计算失败则记录 NA（该 bootstrap 样本无效于驻点计算）
    boot_xs[successes, ] <- c(NA_real_, NA_real_)
  }
}

if (successes < B_success) warning(sprintf("只得到 %d 个成功 bootstrap（尝试 %d 次）", successes, attempts))

# 只使用成功采集到的行来计算置信区间
boot_coefs <- boot_coefs[1:successes, , drop = FALSE]
boot_xs <- boot_xs[1:successes, , drop = FALSE]

alpha <- 0.05
# 对每个系数列按百分位法计算置信区间（注意 na.rm=TRUE 跳过 NA）
ci_coef_lower <- apply(boot_coefs, 2, function(x) quantile(x, probs = alpha/2, na.rm = TRUE))
ci_coef_upper <- apply(boot_coefs, 2, function(x) quantile(x, probs = 1 - alpha/2, na.rm = TRUE))
ci_xs <- apply(boot_xs, 2, function(x) quantile(x, probs = c(alpha/2, 1 - alpha/2), na.rm = TRUE))

# 取用当前主拟合对象的系数（fit 是你之前用 lm 拟合得到的对象）
orig_coefs <- coef(fit)
cat("Coefficient 95% CI (percentile):\n")
for (nm in coef_names) {
  est <- if (nm %in% names(orig_coefs)) as.numeric(orig_coefs[nm]) else NA_real_
  cat(sprintf("%-20s est=%8.4f   [%8.4f, %8.4f]\n",
              nm, est,
              ci_coef_lower[nm], ci_coef_upper[nm]))
}
cat("\nStationary point (95% CI):\n")
cat(sprintf("X1: [%8.4f, %8.4f]\n", ci_xs[1,1], ci_xs[1,2]))
cat(sprintf("X2: [%8.4f, %8.4f]\n", ci_xs[2,1], ci_xs[2,2]))

# 将 bootstrap 结果保存到 CSV，便于后续分析或绘图
write.csv(boot_coefs, "bootstrap_coefs.csv", row.names = FALSE)
write.csv(boot_xs, "bootstrap_stationary_point.csv", row.names = FALSE)
```

##### 3.1.3 计算 P11 和 P10

同时，我们还要自己手动算 $P_{10}$ 和 $P_{11}$，由于 `rsm` 包已经输出了驻点的坐标 $(x_0,\ y_0)$，我们可以很轻松地求得这两个值。

- FPA 的直线方程：$y = P_{10} + P_{11} \times x$；
- $P_{11}$ = $\tan{(\theta)}，\theta = 0.5 \times \arctan(\frac{b_4}{b_3-b_5})$；
- $P_{10}$ = $y_0 − P_{11}\times x_0$。

当然啦，还是可以用代码先把 $P_{11}$ 求了，接上方 [[#3.1.2 计算 CI]] 代码之后，slope 即为 $P_{11}$ 的值。

```R
# 计算 FPA 角度与斜率（按你的系数名调整）
b3 <- orig_coefs["I(X1^2)"]
b4 <- orig_coefs["I(X1 * X2)"]
b5 <- orig_coefs["I(X2^2)"]

phi <- 0.5 * atan2(b4, b3 - b5)
slope <- tan(phi)
cat(sprintf("FPA angle phi = %0.6f (rad), slope = %0.6f\n", phi, slope))
```

#### 3.2. 绘图

在画图时，作者推荐使用 `contour`, `image` 和 `persp` 三个 R 内置的函数来画图。这里主要讲解如何使用 `persp` 绘制响应面，`persp()` 是 base graphics (`graphics` 包) 里画三维表面 (surface) 的函数。它接受 x、y 向量与 z 矩阵 (或在某些包对拟合对象重写了方法)，返回一个投影矩阵 (可用于把 3D 坐标变回 2D 屏幕坐标)，常用于绘制平滑的 3D 响应面，下面是使用 `persp` 包时常用到的参数，

- 指定 x, y, z：
	- x、y，即向量，网格坐标；
	- z，即矩阵，persp 要求 z 是一个尺寸为 length(x) × length(y) 的矩阵，且 z[i,j] 对应 x 向量第 i 个元素和 y 向量第 j 个元素。x[i], y[j] 就是网格上第 i 个 x 值和第 j 个 y 值，z[i,j] 表示在坐标 (x[i], y[j]) 处的高度 (或预测的 Y 值)。
- xlim, ylim, zlim：三轴的绘图区间 (默认为数据范围)。
- xlab, ylab, zlab, main, sub：三轴标签、主标题、副标题。
- **theta：水平旋转角 (度)，控制视点绕 z 轴旋转。**
- **phi：垂直仰角 (度)，控制视点俯仰高度。**
- r：视点距离参数 (与透视相关，通常可留默认)。
- d：透视投影参数 (通常为 1，细调视图深度)。
- expand：z 轴缩放因子 (纵横比调整)。
- col：面片颜色 (单色或按面片数目提供向量实现分面着色)。
- border：面片边界颜色 (set NA 去掉边框)。
- ltheta, lphi：简单的光照方向参数 (用于配合 shade)。
- shade：简单光照/阴影强度 (0–1)。
- box：是否绘制框线 (TRUE/FALSE)。
- axes：是否绘制坐标轴 (TRUE/FALSE)。
- nticks：轴刻度数目。
- ticktype：刻度类型 (例如 "simple" 或 "detailed")。

通常情况下，我们需要先通过 `rsm` 包 或者 `lm` 包 [^10] 拟合一个模型。虽然可以直接使用 `persp` 包画出刚刚拟合出的模型的图 [^11]，但是可能无法调整细节 (比如绘制等高线、设置投影颜色等)，导致函数传递过程出现错误 (虽然我也搞不懂为啥会出错)。因此最好需要先根据现有的 X1(x)、X2(y) 来进行一个预测，生成其他的 X1、X2 (构造预测网络)。随后，根据 `persp` 包的要求，我们需要一个 z 矩阵，根据下面的步骤得到 z 矩阵，

1. 使用 `seq` 函数得到 X1,X2 的等间距网格；
2. 使用 `expand.grid` 函数对 X1 和 X2 两个向量做笛卡尔积，得到所有 (X1, X2) 组合；
3. 将得到的组合丢进拟合好的 rsm 方程中，使用 `predict` 函数预测出对应的 Y(z) 值；
4. 使用 `matrix` 构建 z 矩阵。

随后，为了给每个面着色，需要计算每个面片的值并映射对应的颜色，这一过程需要使用 `colorRampPalette` 等函数。之后，就到了使用 persp 绘图的阶段，给指定 x,y,z 的值后，通过调整 theta, phi 和 expand 来细调图的样式。画 LOC 和 LOIC 曲线的过程其实就是将底面对角线投影到曲面上，这个时候就需要使用 `trans3d` 函数将 2d 转换到 3d(但是由于某种未知错误，只能在本地重新写一个 trans3d 函数用来调用)。

- 考虑到技术问题，目前没有搞懂怎么在曲面上绘制第一主轴~

```R
#导入R包
library(rsm)
# data(package = "rsm") 发现rsm包里没有预制数据集...

# 读取数据，并将数据赋值到data变量中
data <- read.csv("C:/Users/admin/Desktop/暂存/001-留中/R 响应面分析/rsm_data_2factors.csv")

# 定义模型，SO包括线性、交互和平方项
rsm <- rsm(Y ~ SO(X1, X2), data = data)

# 输出拟合的信息
summary(rsm)

# 直接用persp绘制响应面
# persp(rsm, ~ X1 + X2)

# 手动构造预测网络后绘制响应面
# 1. 构造预测网格并得到 z 矩阵
x1r <- seq(min(data$X1), max(data$X1), length.out = 20) # 生成X1的等间距网格，从观测最小值到最大值。决定最终输出的响应面图片中的小方格数量。
x2r <- seq(min(data$X2), max(data$X2), length.out = 20)
grid <- expand.grid(X1 = x1r, X2 = x2r) # 对两个向量做笛卡儿积，得到所有 (X1,X2) 组合的 data.frame。
grid$Ypred <- predict(rsm, newdata = grid) # 用已拟合的 rsm 模型对网格上的每个点做预测，结果存入 grid 的 Ypred 列(即预测出每个数据对对应的Y值)。newdata 的列名必须与模型变量名一致。
zmat <- matrix(grid$Ypred, nrow = length(x1r), ncol = length(x2r)) # 把预测向量重塑为矩阵 zmat。保证 zmat[i,j] 对应 (x1r[i], x2r[j])。

# 2. 计算面片代表值并生成颜色映射(分面着色)
zfacet <- zmat[-1,-1] + zmat[-1,-ncol(zmat)] + zmat[-nrow(zmat),-1] + zmat[-nrow(zmat),-ncol(zmat)] # 计算每个小面片(由四个相邻网格点组成)的“代表值”(四角高度之和)。
zfacet <- zfacet / 4 # 取四角平均，得到面片平均高度(用于给每个面片着色)。
cols <- colorRampPalette(c("#081d58", "#08519c", "#2b8cbe", "#21DD48"))(100) # 深蓝 -> 绿 渐变调色盘，用于映射高度到颜色。
facetcol <- cols[ as.numeric(cut(zfacet, breaks = length(cols))) ] # 把 zfacet 的值按区间分箱(cut)，把每个面片映射到 cols 中对应的颜色索引，得到与面片一一对应的颜色向量 facetcol。

# 3. 保存为 SVG
svg("rsm_persp_custom.svg", width = 10, height = 10) # 打开 SVG 图形设备，后续绘图输出写入该文件(像素大小与分辨率由参数控制)。

# 4. 并绘制美化的 persp
# 4.1 指定x,y向量以及z矩阵
# 4.2 theta为水平旋转角 (度)，控制视点绕 z 轴旋转。
# 4.2 phi为垂直仰角 (度)，控制视点俯仰高度。
# 4.2 expand为z 轴缩放因子 (纵横比调整)。
# 4.2 xlab, ylab, zlab为各个轴的小标题；main为图题
par(tck = -0.01, tcl = -0.2)   # 调整刻度线长度：tck 为图形尺寸比例(负值向外)；tcl 为行高单位(可用负值)
pmat <- persp(x = x1r, y = x2r, z = zmat,
              theta = 330, phi = 30, expand = 1,
              col = facetcol, border = "black", shade = 0.1,
              ticktype = "detailed", xlab = "X1", ylab = "X2", zlab = "Y",
              main = "rsm")


# 把底面两个对角线在曲面上绘出
# 定义了一个trans3d函数，因为之前函数传递的时候出了点问题
trans3d_local <- function(x, y, z, pmat) {
  xyz <- cbind(as.numeric(x), as.numeric(y), as.numeric(z), 1)
  tr <- xyz %*% pmat
  cbind(tr[,1] / tr[,4], tr[,2] / tr[,4])
}

nseg <- 400
xmin <- min(x1r); xmax <- max(x1r)
ymin <- min(x2r); ymax <- max(x2r)

# LOC 红线
loc_x1 <- seq(xmin, xmax, length.out = nseg)
loc_x2 <- seq(ymin, ymax, length.out = nseg)
loc_df <- data.frame(X1 = loc_x1, X2 = loc_x2)
loc_df$Y <- predict(rsm, newdata = loc_df)
loc_xy <- trans3d_local(loc_df$X1, loc_df$X2, loc_df$Y, pmat = pmat)
lines(loc_xy[,1], loc_xy[,2], col = "red", lwd = 2)

# LOIC 蓝线
loic_x1 <- seq(xmin, xmax, length.out = nseg)
loic_x2 <- seq(ymax, ymin, length.out = nseg)
loic_df <- data.frame(X1 = loic_x1, X2 = loic_x2)
loic_df$Y <- predict(rsm, newdata = loic_df)
loic_xy <- trans3d_local(loic_df$X1, loic_df$X2, loic_df$Y, pmat = pmat)
lines(loic_xy[,1], loic_xy[,2], col = "blue", lwd = 2)

# # --- 在图上标注驻点与第一主轴 (FPA) ---
# # 从拟合系数中提取一次项和二次项系数
# coefs <- coef(rsm)
# get_coef <- function(pattern) {
#   idx <- grep(pattern, names(coefs))
#   if (length(idx) == 0) return(0)
#   as.numeric(coefs[idx[1]])
# }

# b1 <- get_coef('^X1$')
# b2 <- get_coef('^X2$')
# bvec <- c(b1, b2)
# c11 <- get_coef('X1\\^2|I\\(X1\\^2\\)|X1:X1')
# c22 <- get_coef('X2\\^2|I\\(X2\\^2\\)|X2:X2')
# c12 <- get_coef('X1:X2|X2:X1')
# Cmat <- matrix(c(c11, c12/2, c12/2, c22), nrow = 2, byrow = TRUE)

# # 用 tryCatch 避免数值错误中断脚本
# tryCatch({
#   xs <- as.numeric(-0.5 * solve(Cmat, bvec))   # 驻点
#   ev <- eigen(Cmat)
#   idxmax <- which.max(abs(ev$values))
#   v <- ev$vectors[, idxmax]
#   v <- v / sqrt(sum(v^2))

#   span <- max(diff(range(x1r)), diff(range(x2r)))
#   tvals <- seq(-span, span, length.out = 300)
#   pts_df <- data.frame(X1 = xs[1] + tvals * v[1], X2 = xs[2] + tvals * v[2])
#   pts_df$Y <- predict(rsm, newdata = pts_df)

#   # 在曲面上绘制第一主轴(粗黑线)
#   fpa_xy <- trans3d_local(pts_df$X1, pts_df$X2, pts_df$Y, pmat = pmat)
#   lines(fpa_xy[,1], fpa_xy[,2], col = "black", lwd = 2)

#  }, error = function(e) {
#   message("无法计算/绘制第一主轴：", e$message)
# })

dev.off() # 关闭设备
```

除了使用 R 内置的函数包进行绘图，还可以使用 `ggplot2` 包来绘制 [^9] 响应面的等高线图 (2D)，或使用 `plotly` 包生成可交互式 3D 视图 (很高级哦)，代码如下。

```R
library(rsm)
library(ggplot2)
# install.packages(c("plotly","htmlwidgets"), repos = "https://cloud.r-project.org", dependencies = TRUE)
library(plotly)
library(htmlwidgets)
data <- read.csv("C:/Users/admin/Desktop/暂存/001-留中/R 响应面分析/rsm_data_2factors.csv")

rsm <- rsm(Y ~ SO(X1, X2), data = data)
summary(rsm)

# 构建预测网络
x1_seq <- seq(min(data$X1), max(data$X1), length.out = 100)
x2_seq <- seq(min(data$X2), max(data$X2), length.out = 100)
x1x2 <- expand.grid(X1 = x1_seq, X2 = x2_seq)
x1x2$y_pred <- predict(rsm, newdata = x1x2)
# 构造 z 矩阵供 plotly 使用(根据上面 expand.grid 的顺序)
zmat <- matrix(x1x2$y_pred, nrow = length(x1_seq), ncol = length(x2_seq))
zmat <- t(zmat)  # 转置以匹配 plotly 的 x,y 顺序(若显示方向不对可去掉 t() 或互换 x/y)


# 绘制响应面(填色)并叠加等高线
response_surface_plot <- ggplot(x1x2, aes(x = X1, y = X2)) +
  geom_raster(aes(fill = y_pred), interpolate = TRUE) +
  geom_contour(aes(z = y_pred), color = "white", bins = 12, size = 0.3) +
  scale_fill_gradientn(colors = c("#081d58","#08519c","#2b8cbe","#41ab5d")) +
  labs(x = "X1", y = "X2", fill = "Predicted Y") +
  theme_minimal()

# 输出2D等高线图,png
ggsave(filename = "rsm_response_surface.png", plot = response_surface_plot,
       width = 8, height = 8, dpi = 300, units = "in")

# 输出3D可交互式视图，html
p3 <- plot_ly(x = x1_seq, y = x2_seq, z = zmat, type = "surface",
              colors = colorRamp(c("#081d58","#08519c","#2b8cbe","#41ab5d"))) %>%
  layout(scene = list(xaxis = list(title = "X1"),
                      yaxis = list(title = "X2"),
                      zaxis = list(title = "Predicted Y")))

# 在交互会话会弹出；也保存为 HTML 文件
htmlwidgets::saveWidget(as_widget(p3), "rsm_response_surface_3d.html", selfcontained = TRUE)
p3
```

#### 3.3. 输出结果分析

在 R 输出的结果里我们通常会看到科学计数法的结果，这一定程度上降低了可读性。~~因此我们可以使用一些函数来指定结果的输出格式~~所以我们可以简单学一下怎么看科学计数法，科学计数法中的 e 表示指数 (exponent)，即 10 的幂次方 [^12]，

- 1.5e+06 表示 1.5 × 10^6 = 1,500,000
- 2.3e-04 表示 2.3 × 10^-4 = 0.00023

如果使用 `rsm` 包来拟合方程，那么 summary 输出的信息应该如下所示。输出信息中我们主要关注第一个表以及驻点。第一个表中包含方程中每一项的回归系数估计值 ($b$)、回归系数的显著性检验 ($t, \ p$)、回归方程的决定系数 ($R^2$)、回归方程的整体显著性检验 ($F, \ p$)。驻点看“Stationary point of response surface”，即 $(x_0,\ y_0)$。

```R
Call:
rsm(formula = Y ~ SO(X1, X2), data = data)

# 表1，其中estimate为回归系数估计值，星号为t检验，表明回归系数显著
             Estimate Std. Error   t value Pr(>|t|)    
(Intercept)  3.00e+00   6.30e-08  47655099   <2e-16 ***
X1           1.50e+00   4.98e-08  30139728   <2e-16 ***
X2          -8.00e-01   4.98e-08 -16074524   <2e-16 ***
X1:X2        6.00e-01   7.04e-08   8524803   <2e-16 ***
X1^2        -5.00e-01   5.34e-08  -9368481   <2e-16 ***
X2^2         3.00e-01   5.34e-08   5621089   <2e-16 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
Multiple R-squared:     1,	Adjusted R-squared:     1 # R方，决定系数，衡量模型对观测变异的解释比例
F-statistic: 2.75e+14 on 5 and 7 DF,  p-value: <2e-16 # F检验，整体回归显著性检验

# 表2
Analysis of Variance Table
Response: Y
            Df Sum Sq Mean Sq  F value Pr(>F)
FO(X1, X2)   2  23.12   11.56 5.83e+14 <2e-16 # first-order(一次项)相关的平方和(主效应)。
TWI(X1, X2)  1   1.44    1.44 7.27e+13 <2e-16 # two-way interaction(交互项)平方和(X1:X2)。
PQ(X1, X2)   2   2.68    1.34 6.77e+13 <2e-16 # pure quadratic(纯二次项 X1^2、X2^2)平方和。
Residuals    7   0.00    0.00                # 残差与拟合适配性检验项。
Lack of fit  3   0.00    0.00      Inf <2e-16 # 残差与拟合适配性检验项。
Pure error   4   0.00    0.00                # 残差与拟合适配性检验项。
# 若 Residuals/Pure error = 0 或极小，Lack of fit 的 F 可能为 Inf(数值上分母为 0 或接近 0)，表示没有可用于检验缺拟合的纯误差(数据刚好落在模型上)。

Stationary point of response surface:  # 驻点
    X1     X2 
 1.437 -0.104 

Eigenanalysis:
eigen() decomposition
$values
[1]  0.4 -0.6
# valuesvalues：C 矩阵(二次项矩阵)的特征值(例：[0.4, -0.6])。符号决定驻点性质：
# - 全为正 → 驻点是极小值(局部最小)。
# - 全为负 → 驻点是极大值(局部最大)。
# - 异号混合 → 驻点是鞍点(saddle)。

$vectors 
     [,1]   [,2]
X1 -0.316 -0.949
X2 -0.949  0.316
# 对应的特征向量，给出在 X1–X2 空间中主曲率方向(主轴方向)。每列是一个特征向量，第一列对应第一个特征值(0.4)，第二列对应第二个(-0.6)。特征向量的方向在图上即为“主轴”(FPA/first principal axis 等)，通常取绝对特征值最大的那一列作为“第一主轴”的方向(表示最大曲率方向)。
```

而各个回归系数以及驻点的 $CI$，则需要跑 bootstrap 代码得到，可见 [[#3.1.2 计算 CI]] 部分代码。在我们看回归系数的 CI 时要注意其是否过 0 点 [^13]，若置信区间过 0 点，则意味着无法拒绝零假设。但是对于驻点来说，如果置信区间包含 0 点，则意味着其位置不明确 (至于其重要性，我也不知道，过不过 0 点都无所谓？)。

$P_{11},\ P_{10}$ 需要手动计算 (其中 $P_{11}$ 可以先用代码算)，如果 $P_{11}$ 是使用代码算出来的，那么最终输出的 slop 值即为 $P_{11}$，而 $P_{10}$ 则需要将 $x_0,\ y_0, P_{11}$ 全部带入到 FPA 的方程 ($y=P_{10}+P_{11}\times x$) 后算得。

### 4. 结果报告

参考 Shanock et al. (2010)[^14] 与 Humberg et al. (2019)[^8] 的规范，主要分为以下步骤。

1. $X$、$Y$ 是否已均值中心化并在方法中说明：$X$、$Y$ 是否均值中心化 (必需说明)；是否标准化 (如 z-score)。
2. $b_0 \dots b_5$ 全部列出并给出 $CI$ 或 $p$ 值：$b_0, b_1, b_2, b_3, b_4, b_5$ 的估计值、标准误、$t$ 值或 $z$ 值、$p$ 值 (或 95% $CI$[^13])。
3. $a_1 \dots a_4$ (LOC/LOIC) 列出并讨论：$a_1$($= b_1 + b_2$) (LOC 的一阶斜率), $a_2$ ($= b_3 + b_4 + b_5$) (LOC 的二阶曲率), $a_3$ ($= b_1 − b_2$) (LOIC 的一阶斜率), $a_4$ ($= b_3 − b_4 + b_5$) (LOIC 的二阶曲率)。
4. 驻点 (stationary point, $(x_0,y_0)$) 与 FPA ($P_{10}$, $P_{11}$) 列出并给出 $CI$(驻点的置信区间体现的是其位置在哪个象限，如果过 0，则意味着驻点位置不确定)。
	- FPA 的直线方程：$y = P_{10} + P_{11} \times x$；
	- $P_{11}$ = FPA 的斜率 (旋转/倾斜)，通常等于 $\tan{(\theta)}，\theta = 0.5 \times \arctan2(\frac{b_4}{b_3-b_5})$；
	- $P_{10}$ = 截距，等于 $y_0 − P_{11}\times x_0$。
5. $P_{10}=0、P_{11}=1$ 的检验结果 (并给出联合检验)：解梯度方程 [^15] 得到的坐标，给出估计值与 $CI$。
6. 3D/等高线图中标注 LOC/LOIC/FPA/驻点；
7. $CI$ 的计算方法 (Delta/Bootstrap) 与重复次数说明：指出 $CI$ 的计算方式 (Delta 方法 / Bootstrap)，如果样本量有限建议使用 Bootstrap。

除此之外，还需要汇报一些公式。

- 回归方程：$z = b_0 + b_1 X + b_2 Y + b_3 X^2 + b_4 X Y + b_5 Y^2$ (及其 $R^2$ 和整体回归显著性检验)
- LOC$(X=Y)$ 上： $z = b_0 + (b_1+b_2)X + (b_3+b_4+b_5)X^2 \Rightarrow a_1 = b_1+b_2;\ a_2 = b_3+b_4+b_5$
- LOIC$(X=−Y)$ 上： $z = b_0 + (b_1−b_2)X + (b_3−b_4+b_5)X^2 \Rightarrow a_3 = b_1−b_2;\ a_4 = b_3−b_4+b_5$

> [!quote] 文本报告示例
> 我们基于均值中心化的 $X$ 与 $Y$ 拟合二次多项式模型：$z = b_0 + b_1X + b_2Y + b_3X^2 + b_4XY + b_5Y^2$。回归结果见表 1($b_1 \dots b_5$ 均给出)。模型解释变异 $R^2 = 0.27 \ (p < 0.001)$。沿 LOC$(X = Y)$ 的一阶斜率 $a_1 = 0.70\ (95\% CI [0.30, 1.10])$，二阶曲率 $a_2 = −0.30(95\% CI [−0.52, −0.08])$，表明 $\dots$ (解释)。沿 LOIC$(X = −Y)$ 的一阶与二阶参数为 $a_3 =\dots,\ a_4 = \dots$ (表 2)。
>
> 驻点位于 $(x_0, \ y_0) = (1.09, 1.55)\ (95\% CI [xx,\ xx])$，FPA 由 $y = P_{10} + P_{11} x$ 定义，其中 $P_{10} = −0.46\ (95\% CI [xx,\ xx]),\ P_{11} = 1.84\ (95\% CI [xx, \ xx])$。
>
> 检验 $P_{10} = 0$ 与 $P_{11} = 1$ 的结果均被拒绝 ($P_{10}: p = 0.003;\ P_{11}: p < 0.001$)，表明 FPA 与 LOC 不重合；等高线与脊线见图 1 (图中同时标注 $LOC$、$LOIC$、$FPA$)。
>  - 如果 $P_{10} \approx 0$ 且 $P_{11}\approx1$，则直接写“$FPA$ 与 $LOC$ 重合 ($P_{10} = 0, P_{11} = 1$ 未被拒绝)”，并据此讨论“相合效应”。
> 
> 尽管 LOC$(X = Y)$ 上存在显著曲率 ($a_2 = −0.30$)，FPA 与 LOC 并不重合 ($P_{10} = −0.46, p = 9.12;\ P_{11} = 1.84, p < 0.001$)。因此样本中的最优组合并非简单的“$X \approx Y$”，而是沿着 FPA ($y \approx −0.46 + 1.84 x$) 出现 (图 1)。”

[^1]: 👏[R数据分析：多项式回归与响应面分析的理解与实操 - 知乎](https://zhuanlan.zhihu.com/p/633986352)
[^2]: [响应曲面设计(基本原理)-CSDN博客](https://blog.csdn.net/wanganqiqi/article/details/138159758)
[^3]: [响应曲面(RSM)设计方法简介 - 知乎](https://zhuanlan.zhihu.com/p/8926803361)
[^4]: 根据豆包解释，多元线性回归只能捕捉“独立的线性回归”，即它假设 $X_1$ 和 $X_2$ 对 $Y$ 的影响是 “互不干扰的线性关系”，且其回归方程中不存在 $X_1$ 和 $X_2$ 的交互项，因此难以体现“$X_1$ 和 $X_2$ 的协同作用”。
[^5]: 即每个自变量取多个水平，所有组合都做实验，比如 2 个自变量各取 5 个水平，需做 5×5=25 组实验 (CCD 仅需 13 组)。
[^6]: 见 `short-memory/本硕中组会20251024`。
[^7]: Rodrigues, A. C. (2021). Response surface analysis: A tutorial for examining linear and curvilinear effects. _Revista De Administração Contemporânea_, _25_(6), e200293. [https://doi.org/10.1590/1982-7849rac2021200293.en](https://doi.org/10.1590/1982-7849rac2021200293.en)
[^8]: Humberg, S., Nestler, S., & Back, M. D. (2019). Response surface analysis in personality and social psychology: Checklist and clarifications for the case of congruence hypotheses. _Social Psychological and Personality Science_, _10_(3), 409–419. [https://doi.org/10.1177/1948550618757600](https://doi.org/10.1177/1948550618757600)
[^9]: [R语言高级分析：掌握响应面方法的6个实战技巧(立即提升你的数据分析能力) - CSDN文库](https://wenku.csdn.net/column/5x9872ff26)
[^10]:` fit <- lm(Y ~ X1 + X2 + I(X1^2) + I(X2^2) + I(X1*X2), data = data)`，其中 I 是方程中每一个二次项。
[^11]: 根据 rsm 包的帮助文档，rsm::persp 可以自动在 X1、X2 空间构造预测网格 (默认分辨率)，并用 predict(rsm, newdata=grid) 计算高度，调用 graphics::persp 绘图并返回投影矩阵 (pmat)。因此想要快速知道响应面长什么样，可以先用 `persp(rsm, ~X1+X2)` 绘制响应面图。
[^12]: [R语言输出结果中的e是什么意思为什么会出现以及如何正确解读和格式化科学计数法以避免数据分析中的常见错误本文提供实用指南帮助用户理解并控制输出格式 - 云原生实践](https://www.oryoy.com/news/r-yu-yan-shu-chu-jie-guo-zhong-de-e-shi-shen-me-yi-si-wei-shen-me-hui-chu-xian-yi-ji-ru-he-zheng-que.html)
[^13]: 见 [[心理统计基础#5. 参数估计]]。对于回归分析，如果置信区间过 0 则无法拒绝零假设。
[^14]: Shanock, L. R., Baran, B. E., Gentry, W. A., Pattison, S. C., & Heggestad, E. D. (2010). Polynomial regression with response surface analysis: A powerful approach for examining moderation and overcoming limitations of difference scores. _Journal of Business and Psychology_, _25_(4), 543–554. [https://doi.org/10.1007/s10869-010-9183-4](https://doi.org/10.1007/s10869-010-9183-4)
[^15]: 解线性方程 (`[[],[]]` 为矩阵写法) $\left\{\begin{matrix}A=[[2b_3,b_4],[b_4,2b_5]] \\ [x_0;y_0]=-A^{-1}[b_1;b_2]\end{matrix}\right.$